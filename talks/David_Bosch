The Convex Gaussian Min-Max Theorem (CGMT) is a powerful method for the study of min-max optimization problems over bilinear Gaussian forms. It provides an alternative optimization problem whose statistical properties are tied to that of the target problem. We prove a generalization of the CGMT to a family of problems in machine learning (ML) with correlated entries in the data matrix. This family includes various familiar examples of problems with shared weights or repeated features.
